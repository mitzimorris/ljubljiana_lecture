{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be869160",
   "metadata": {},
   "source": [
    "## Align, combine, subset EPA radon, uranium data and US Census GIS data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06819c51-5a2c-4c93-a38f-65090a52766a",
   "metadata": {},
   "source": [
    "### Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0ea6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import all libraries used in this notebook\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# GIS libs\n",
    "import geopandas as gpd\n",
    "import libpysal as sa\n",
    "# plotting libs\n",
    "import matplotlib.pyplot as plt\n",
    "import splot as splt\n",
    "import plotnine as p9\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68172a6e",
   "metadata": {},
   "source": [
    "### State/EPA Residiental Survey (SRRS) datasets\n",
    "\n",
    "The rawest form of the radon data was collected and archived by Phil Price and is available here:\n",
    "http://www.stat.columbia.edu/~gelman/arm/examples/radon_complete\n",
    "\n",
    "\n",
    "* The documentation is in file http://www.stat.columbia.edu/~gelman/arm/examples/radon_complete/SRRSdoc.pdf\n",
    "\n",
    "* There are 5 files, srrs1.dat through srrs5.dat  - but data is duplicated between them.\n",
    "\n",
    "* This directory also contains data from both national survey - NRRS - and state surveys - cf. https://link.springer.com/article/10.1007/BF02034901.   This is in a different format and is\n",
    "not used in Gelman and Hill analysis.\n",
    "\n",
    "* README notes that files are old backups, things may be missing.\n",
    "\n",
    "The combined de-duplicated SRRS dataset is in file  [srrs_all.csv](data/srrs_all.csv)\n",
    "\n",
    "*State counties and tribal lands*\n",
    "\n",
    "The SRRS dataset contains observations taken from Indian lands.\n",
    "The county-level information for these entries doesn't line up with US FIPS data -\n",
    "the names and county codes don't align.\n",
    "Indian lands have column 'STATE' code R5, R6, R7, RB, RC, RN.\n",
    "The regions cross state boundaries - for example,\n",
    "EPA region 5 covers Indian lands in MN, WI, and MI:\n",
    "https://www.epa.gov/sites/default/files/2015-08/documents/r5-tribal-land-map.pdf.\n",
    "\n",
    "Data in state counties in file [radon_all_states.csv](data/radon_all_states.csv).\n",
    "\n",
    "Data from Indian lands is in file [radon_indg_lands.csv](data/radon_indg.csv).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3798cf-5e30-4531-afad-d348fc5b1449",
   "metadata": {},
   "source": [
    "### US census county boundaries GIS files\n",
    "\n",
    "The US Census provides shapefiles for the US, including Alaska, Hawaii, and territories.  We can use these to visualize radon and uranium levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07daae-74a1-431a-8255-04bd1f29670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shpfile = os.path.join('geo_data','cb_2018_us_county_20m', 'cb_2018_us_county_20m.shp')\n",
    "us_geodata = gpd.read_file(shpfile)\n",
    "# GEOID should be numeric\n",
    "us_geodata = us_geodata.astype({'GEOID': 'int32'}, copy=False)\n",
    "print(us_geodata.shape[0])\n",
    "us_geodata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548b6aa",
   "metadata": {},
   "source": [
    "### EPA/State Residential Radon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c67d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_radon = pd.read_csv(os.path.join('data','radon_all_counties.csv'),\n",
    "                     usecols=['state', 'stfips', 'floor', 'activity', 'cntyfips'],\n",
    "                     skipinitialspace=True,    # CSV file has spaces after delimiter, ignore them\n",
    "    ).convert_dtypes()\n",
    "print(us_radon.shape)\n",
    "us_radon.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89b204",
   "metadata": {},
   "source": [
    "**datacleanup**\n",
    "\n",
    "Colorado and CT have data with cntyfips codes '0' and '999'.   Dropping for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62fa643",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_radon.drop(us_radon[us_radon.cntyfips==0].index, inplace=True)\n",
    "us_radon.drop(us_radon[us_radon.cntyfips==999].index, inplace=True)\n",
    "print(us_radon.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78557c8-db6a-4bbd-a6a4-071e9d013ec8",
   "metadata": {},
   "source": [
    "### US county soil uranium levels\n",
    "\n",
    "Also distributed from Gelman website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cdc9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_uranium = pd.read_csv(os.path.join('data','raw_uranium.csv'),\n",
    "                        usecols=['st', 'stfips', 'ctfips', 'Uppm'],\n",
    "                        skipinitialspace=True,\n",
    "                        ).drop_duplicates().convert_dtypes()\n",
    "print(us_uranium.shape[0])\n",
    "us_uranium.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93402d8a-4b4d-4e92-bd69-6fa008045cc3",
   "metadata": {},
   "source": [
    "### Join and merge tables using US FIPS codes\n",
    "\n",
    "To join or merge tables, we need to create a common key in both, then\n",
    "use the [DataFrame.merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) method.\n",
    "\n",
    "\n",
    "We have three datasets:  SRRS survey data, soil uranium measurements, and geodata.\n",
    "All files use different capitalization and punctuation for county names.\n",
    "Therefore we rely on \n",
    "[FIPS code](https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt),\n",
    "which uniquely identify geographic areas. \n",
    "The US census datasets have \"GEOID\" code, the first 2 digits of which are the state FIPS code, the last 3 are the county-level FIPS code.\n",
    "The other datasets have separate columns for stats and county codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41668fc1-a0c9-41a0-9ae7-9b44cb4127dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create merge column\n",
    "us_uranium['FIPS'] = us_uranium.stfips*1000 + us_uranium.ctfips\n",
    "us_radon['FIPS'] = us_radon.stfips*1000 + us_radon.cntyfips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c27212",
   "metadata": {},
   "source": [
    "### County level information:   uranium, number of homes in radon survey, census county name\n",
    "\n",
    "We create a new table which contains county-level information from across the three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29923eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_counties = us_uranium.merge(us_geodata[['GEOID', 'NAME']],\n",
    "                               how='inner', left_on='FIPS', right_on='GEOID')\n",
    "\n",
    "homes = us_radon.value_counts(subset=['FIPS'], sort=False).to_frame().reset_index()\n",
    "homes.rename(columns={0:'homes'}, inplace=True)\n",
    "\n",
    "us_counties = us_counties.merge(homes, how='left', on='FIPS')\n",
    "us_counties.fillna(0, inplace=True)\n",
    "\n",
    "us_counties.drop(columns=['stfips', 'ctfips', 'GEOID'], inplace=True)\n",
    "us_counties.rename(columns={'st': 'state', 'NAME':'county', 'Uppm':'uranium'}, inplace=True)\n",
    "\n",
    "print(us_counties.shape[0])\n",
    "us_counties.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a51fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_counties[us_counties.state=='MN'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a1505f",
   "metadata": {},
   "source": [
    "#### Put data on log scale\n",
    "\n",
    "Following Gelman and Hill chapter 4, section 4, we work with data on the log scale,\n",
    "for two reasons\n",
    "\n",
    "+ the outcome variable log_radon is always positive.\n",
    "+ it provides modeling flexibility.\n",
    "\n",
    "We know from geology that both radon measurements and soil uranium levels are always greater than zero,\n",
    "however a few radon measurements in the EPA dataset are 0.\n",
    "In order to be able to work with these measurements on the log scale, we replace 0 with 0.1,\n",
    "which corresponds to a low radon level (following Gelman and Hill)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_radon['radon'] = us_radon.activity.apply(lambda x: x if x > 0.1 else 0.1)\n",
    "us_radon['log_radon'] = np.log(us_radon['radon'])\n",
    "us_radon.drop(columns=['activity', 'stfips', 'cntyfips'], inplace=True)\n",
    "us_radon.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_counties.uranium.fillna(0.1, inplace=True)\n",
    "us_counties['u'] = us_counties.uranium.apply(lambda x: x if x > 0.1 else 0.1)\n",
    "us_counties['log_uranium'] = np.log(us_counties['u'])\n",
    "us_counties.drop(columns=['u'], inplace=True)\n",
    "us_counties.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b137c20",
   "metadata": {},
   "source": [
    "### Restrict dataset to Minnesota\n",
    "\n",
    "In order to work with just the data from Minnesota, we use a \n",
    "use a conditional expression to [filter specific rows of a dataframe](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html#how-do-i-filter-specific-rows-from-a-dataframe), combined with operation [reset_index(drop=True)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html?highlight=reset_index#pandas.DataFrame.reset_index) so that the rows are indexed starting from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_radon = us_radon[us_radon['state']=='MN'].reset_index(drop=True)\n",
    "mn_radon.drop(columns=['state'], inplace=True)\n",
    "mn_radon = mn_radon.merge(us_counties[['FIPS', 'county']], on='FIPS')\n",
    "mn_radon = mn_radon.sort_values(by='county', axis=0).reset_index(drop=True)\n",
    "mn_radon.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_counties = us_counties[us_counties['state']=='MN'].reset_index(drop=True)\n",
    "mn_counties.drop(columns=['state'], inplace=True)\n",
    "mn_counties.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c5f573-e008-4aa4-bd15-74603df7edec",
   "metadata": {},
   "source": [
    "#### Unique county ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e68449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# super clunky to index offset from 1\n",
    "mn_counties.reset_index(inplace=True)\n",
    "mn_counties['county_id'] = mn_counties.index + 1\n",
    "mn_counties.drop(columns=['index'], inplace=True)\n",
    "mn_counties.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91947f1",
   "metadata": {},
   "source": [
    "Add county ids to radon data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_radon = mn_radon.merge(mn_counties[['FIPS', 'county_id']], on='FIPS')\n",
    "mn_radon.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c9602",
   "metadata": {},
   "source": [
    "**Save as CSV files**\n",
    "\n",
    "These files are already part of this notebook, therefore calls to the  [pandas.to_csv](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html?highlight=to_csv#pandas.DataFrame.to_csv) method have been commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04aea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment as needed\n",
    "# mn_radon.to_csv(os.path.join('data', 'mn_radon.csv'), index=False)\n",
    "# mn_counties.to_csv(os.path.join('data', 'mn_counties.csv'), index=False)\n",
    "\n",
    "# us_radon.to_csv(os.path.join('data', 'us_radon.csv'), index=False)\n",
    "# us_counties.to_csv(os.path.join('data', 'us_counties.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3a42d-cdb0-44e3-adf1-b033bd39ebd6",
   "metadata": {},
   "source": [
    "### Add GeoSpatial Information for US Counties\n",
    "\n",
    "If we want to build a spatial model which allows for local pooling of information between nearby counties, we need to create a neighbor graph over all the counties in Minnesota.\n",
    "\n",
    "**GIS Data**\n",
    "\n",
    "Geographic information systems (GIS) data is any item which has a geographic location, either a single point or a set of bounding polygons.  In order to manage, analyze, and visualize GIS data, we use specialized packages which can do the geographic math.  In this notebook we use the following packages:\n",
    "\n",
    "- GeoPandas - manages a set of GIS records in tabular format\n",
    "- libpysal - spatial analysis package which can analyze distance between locations\n",
    "\n",
    "Cartographic data (maps) are encoded as a set of records, one per map region.  The [shapefile format](https://en.wikipedia.org/wiki/Shapefile) is an open specification used to insure interoperatility among GIS software packages.  When items in a dataset contain location labels, it is necessary to obtain a set of shapefiles for the corresponding map.\n",
    "\n",
    "The shapefiles for US counties are available from the [US Census Bureau](https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html).\n",
    "For this analysis, we are using shapefiles where the boundary information is specified with the lowest possible resolution; this greatly speeds up analysis and plotting.\n",
    "These can be downloaded via URL: https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_county_20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d07b9-d9d9-4d3d-a62c-209dffe009df",
   "metadata": {},
   "outputs": [],
   "source": [
    "shpfile = os.path.join('geo_data','cb_2018_us_county_20m', 'cb_2018_us_county_20m.shp')\n",
    "us_geodata = gpd.read_file(shpfile).convert_dtypes()\n",
    "us_geodata = us_geodata.astype({'GEOID': 'int32'}, copy=False)\n",
    "us_geodata.drop(columns=['COUNTYFP', 'COUNTYNS', 'AFFGEOID', 'NAME', 'LSAD', 'ALAND', 'AWATER'], inplace=True)\n",
    "us_geodata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925d0dfe-4c00-43cb-8ca4-527dd63c185e",
   "metadata": {},
   "source": [
    "For this analysis, we restrict our analysis to the counties in Minnesota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce6122a-7306-4596-bd88-35dbfdcf3462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get MN subset, add county-level information\n",
    "mn_geodata = us_geodata[us_geodata['STATEFP']=='27'].copy()\n",
    "mn_geodata = mn_geodata.merge(mn_counties[['FIPS', 'county', 'county_id', 'log_uranium']],\n",
    "                               how='inner', left_on='GEOID', right_on='FIPS')\n",
    "mn_geodata.drop(columns=['STATEFP', 'GEOID'], inplace=True)\n",
    "mn_geodata = mn_geodata.sort_values(by='county_id', axis=0).reset_index(drop=True)\n",
    "mn_geodata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e95681-8f4c-4937-81b8-c47ac166d20a",
   "metadata": {},
   "source": [
    "To check our work, we plot the counties in Minnesota, colored by log uranium level and labeled by county name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a35a71-0780-4052-a82a-05061eb7f1fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_pts = mn_geodata.geometry.centroid.to_crs(mn_geodata.crs)\n",
    "(p9.ggplot()\n",
    " + p9.geom_map(data=mn_geodata, mapping=p9.aes(fill='log_uranium'), alpha=0.7)\n",
    " + p9.geom_text(mapping=p9.aes(x=county_pts.x, y=county_pts.y, label=list(mn_geodata.county)),\n",
    "                size=6, ha='center')\n",
    " + p9.theme(figure_size=(10, 8))\n",
    " + p9.scale_fill_cmap(cmap_name='viridis')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b3fd47-c5a0-4c36-ae28-c27c278804f6",
   "metadata": {},
   "source": [
    "We need to find the set of pairs of adjacent counties; to do this we use `libpysal` which parses the bounding polygons to find all counties which have a common border of non-zero length, (\"Rook\" metric).  To check our work, we plot the resulting neighbor graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68cc050-7e65-4f70-9782-0b0e52cc8cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neighbors are counties which have a common line boundary\n",
    "from splot.libpysal import plot_spatial_weights\n",
    "from libpysal.weights.contiguity import Rook\n",
    "mn_nbs = Rook(mn_geodata['geometry'])\n",
    "plot_spatial_weights(mn_nbs, mn_geodata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29378142-32c5-43a9-95c3-853cb3bc6b45",
   "metadata": {},
   "source": [
    "As a sanity check, we get the edges list labeled by county name check that the upper rightmost county \"Lake\" is adjacent to \"Cook\" county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dcaeea-2209-4013-b2ab-dde42b5f2fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mn_nbs_names = Rook(mn_geodata['geometry'], ids=mn_geodata['county'].tolist())\n",
    "mn_nbs_edges_names =  mn_nbs_names.to_adjlist(remove_symmetric=True).reset_index(drop=True)\n",
    "mn_nbs_edges_names[mn_nbs_edges_names['focal']=='Cook']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe44d25-434a-43aa-a47a-4387bde6a37c",
   "metadata": {},
   "source": [
    "We extract neighbor relationships as an edgelist and output this as a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c01420-75aa-45ee-b741-41e6c0757582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mn_nbs_edges =  mn_nbs.to_adjlist(remove_symmetric=True).reset_index(drop=True)\n",
    "mn_nbs_edges.head(3)\n",
    "\n",
    "node1 = (mn_nbs_edges['focal'] + 1).tolist()\n",
    "node2 = (mn_nbs_edges['neighbor'] + 1).tolist()\n",
    "\n",
    "mn_nbs_dict = { 'node1' : node1, 'node2' : node2, 'J_edges' : len(node1) }\n",
    "\n",
    "from cmdstanpy import write_stan_json\n",
    "write_stan_json(\"mn_nbs.json\", mn_nbs_dict)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
